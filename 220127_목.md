# 이재학

# **(06강) 모델 불러오기**

 (학습 결과를 저장할 필요가 있다!)

---

- model.save()
    - 학습의 결과를 저장하기 위한 함수
    - 모델 형태 , 파라미터 저장
    - 모델 학습 중간 과정의 저장을 통해 최선의 결과모델을 선택
    - 만들어진 모델을 외부 연구자와 공유하며 학습 재연성 향상
- checkpoints
    - 학습 중간 결과를 저장하여 최선의 결과를 선택
    - earlystopping 기법 사용시 이전 학습의 결과물을 저장
    - loss와 metric 값을 지속적으로 확인하여 저장
    - 일반적으로 epoch, loss,metric을 함께 저장하여 확인
    - colab에서 지속적인 학습을 위해 필요
- Transfer learning(남이 만든 모델을 쓰고 싶다)
    - 다른 데이터셋으로 만든 모델을 현재 데이터에 적용
    - 현재의 딥러닝에서 가장 일반적인 학습 기법 (CV : Resnet , NLP : BERT, Hugging Face)
    - backbone architecture가 잘 학습도니 모델에서 일부분만 변경하여 학습을 수행함
- Freezing
    - pretrained model 활용 시 모델의 일부분을 frozen 시킴
    
    ```python
    vgg = models.vgg19(pretained=True).to(device)    # vgg19 모델을 vgg에 할당하기
    
    class MyNewNet(nn.Module):
    	def __init__(self):
    		super(MyNewNet, self).__init__()
    		self.vgg19=models.vgg19(pretrained=True) 
    		self.linear_layers=nn.Linear(1000,1)         # 모델의 마지막에 Linear Layer 추가
    	
    	def forward(self, x):
    		x=self.vgg19(x)
    		return self.linear_layers(x)
    
    for param in my_model.parameters():              # 마지막 Linear 레이어를 제외하고 frozen
    		param.requires_grad = False
    for param in my_model.linear_layers.parameters():
    		param.requires_grad = True
    
    ```
    
- torch summary : 모델 정보와 파라미터 알 수 있음
- pth보단 pt 확장자!
- 되도록이면 기존 모델 안 바꾸고 레이어를 추가하는 형식으로!

---

# **(07강) Monitoring tools for PyTorch**

(긴 학습 시간 동안 **기다림의 기록** 필요!)

---

- TensorBoard vs wandb
- TensorBoard
    - Tensorflow의 프로젝트로 만들어진 시각화 도구
    - 학습 그래프, metric , 학습 결과의 시각화 지원
    - PyTorch도 연결 가능 → DL 시각화 핵심 도구
    - add_함수
        - scalaer : metric 등 상수 값을 표시
        - graph : 모델의 computational graph 표시
        - histogram : weight 등 값의 분포를 표현
        - image : 예측 값과 실제 값을 비교 표시
        - mesh : 3d 형태의 데이터를 표현하는 도구
    
    ```python
    import os
    logs_base_dir= "logs"             #디렉토리 생성
    os.makedirs(~)
    
    from torch.utils.tensorboard import SummaryWriter
    import numpy as np
    
    writer=SummaryWriter(logs_base_dir)     #기록 생성 객체 SummaryWriter 생성
    for _ in range(100):
    	writer.add_scaler("Loss/train',~)     #add_scalar 함수 : scalar 값을 기록
    	~
    	~
    	~
    wrriter.flush()   #값 기록(disk에 쓰기)
    
    %load_ext tensorboard   #주피터 상에서 텐서보드 수행
    %tensorboard --logdir(logs_base_dir)  #파일 위치 지정
    ```
    
- weight & biases (wandb)
    - 머신러닝 실험을 원활히 지운하기 위한 상용도구
    - 협업 , code versioning, 실험 결과 기록 등 제공
    - MLOps의 대표적인 툴로 저변 확대 중
    
    ```python
    !pip install wandb -q
    
    config={"epochs" :EPOCHS , "batch_size":BATCH_SIZE, "learning_rate" : LEARNING_RATE}
    wandb.init(project='jh',config=config)
    
    for e in range(1,EPOCHS+1):  
    	epoch_loss=0
    	epoch_acc=0
    	for X_batch, y_batch in train_dataset:
    			~
    			~
    
    wandb.log({'accuracy' : train_acc , 'loss' : train_loss}) #텐서보드의 add_scalar 같은 것
    ```
    

---

# **(08강) Multi-GPU 학습**

(어떻게 GPU 다룰 것 인가!)

---

- 개념정리
    - Node(system) : 1개의 컴퓨터
    - Single vs Multi
    - GPU vs Node
    - Single Node Single GPU
    - Single Node Multi GPU(현실)
    - Multi Node Multi GPU (궁극의 목표)
- Model parallel
    - 다중 CPU에 학습을 분산하는 두가지 방법
        - 모델 나누기
        - 데이터 나누기
    - 모델을 나누는 것은 예전 부터 씀 (Alexnet → 인공지능 기말 대체 과제)
    - 모델의 병목현상, 파이프라인의 어려움 등으로 인해 모델 병렬화는 고난이도 과제
    
     
    
    ```python
    class ModelParrelResNet50(ResNet):
    		def __init__(self, ~ ):
    				pass
    				
    				self.seq1=nn.Sequential(~).to('cuda:0')     #첫번째 모델을 cuda 0에 할당
    				
    				self.seq2=nn.Sequential(~).to('cuda:1')     #두번째 모델을 cuda 1에할당
    
    		def forward(self,x):
    				x=self.seq2(self.seq1(x).to('cuda:1'))      #두 모델을 연결
    		    pass
    ```
    
- Data parallel
    - 데이터를 나눠 GPU에 할당 후 결과의 평균을 취하는 방법
    - minibatch 수식과 유사한데 한번에 여러 GPU에서 수행
    - Pytorch 에서는 두 가지 방식을 제공
        - DataParrel : 단순히 데이터를 분배한 후 평균을 취함 → GPU사용 불균형 문제 발생, Batch 사이즈 감소( 한 GPU가 병목 현상 → GPU 한개가 많은 일을 하니.. 불쌍..) ,GIL(Global Interpreter Lock)
        
        ```python
        parallel_model=torch.nn.DataParallel(model)
        ```
        
        - DistributiedDataParallel : 각 CPU마다 process생성하여 개별 GPU에 할당 → 기본적으로 DataParallel로 하나 개별적으로 연산의 평균을 냄
        
        ```python
        train_sampler=torch.utils.data.distributed.DistributedSampler(train_data)
        shuffle=False
        pin_memory=True
        
        trainloader= torch.utils.data.DataLoader(train_data, batch_size=20,shuffle=True,
        																				pin_memory, num_workers=3,
        																				shuffle=shuffle,sampler=train_sampler)
        
        # pin_memory -> tensor를 cpu에서 gpu로 올릴 때,
        # num_workers = 4 x GPU
        ```
        

---

# **(09강) Hyperparameter Tuning**

---

- Hyperparameter Tuning
    - 예전에는 표준이 없으니 “**손 맛”**일 정도로 기준이 없었음!
    - 모델 스스로 학습하지 않는 값은 사람이 지정(learning rate, 모델의 크기 optimizer ,batch size 등)
    - 하이퍼 파라미터에 따라 값이 좌우될 수 있음(인공지능 과제 떄 배치사이즈가 엄청난 역할 했음)
    - 마지막 0.01이라도 늘리고자 할 때 해보자! (무엇보다 중요한건 데이터!)
- Hyperparameter Tuning 방법
    - grid vs random
        - random → 성능 좋은 곳에서 grid 하는 것이 좋은 방법
    - 최근에는 베이지안 기반 기법들이 주도**(BOHB)**
- Ray
    - multi-node multi processing 지원 모듈
    - 머신러닝 / 딥러닝 병렬 처리를 위해 개발된 모듈
    - 기본적으로 현재의 분산병렬 머신러닝/딥러닝 모듈의 표준
    - Hyperparameter Search를 위한 다양한 모듈 제공
    - **하려고 하는 모델은 반드시 학습하는 과정이 처음부터 끝까지 함수로 되어 있어야 Ray가 나중에 불러올 수 있음!**

---

# **(10강) PyTorch Troubleshooting**

(FAQ 같은 느낌!)

---

- OOM(Out Of Memory)이 해결하기 어려운 이유
    - 왜 발생했는데?
    - 어디서 발생했는데?
    - Error backtracking하려면 이상한 미로에 빠짐
    - 메모리 이전상황의 파악이 어려움
- Batch Size 줄이고 → GPU 청소하고 → 실행하면 가장 깔끔한 치료법(이게 된다면 코드가 잘못된 건 아님!)
- GPUtil 사용!
    - nvidia-smi 처럼 GPU의 상태를 보여주는 모듈
    - Colab은 환경에서 GPU 상태 보여주기 편함
    - iter마다 메모리가 늘어나는지 확인!
    
    ```python
    !pip install GPUtil
    
    import GPUtil
    GPUtil.showUtilization()
    ```
    
- torch.cuda.empty_cache()
    - **학습전에 empty_cache 하는 것 권장!**
    - 사용되지 않은 GPU상 cache를 정리
    - 가용 메모리를 확보
    - del과는 구분이 필요
    - reset 대신 쓰기 좋은 함수
    
    ```python
    from GPUtil import showUtilization as gpu_usage
    
    gpu_usage()
    
    tensorlist=[]
    for x in range(10):
    	tensorlist.append(torch.randn(1000000,10).cuda())
    
    gpu_usage()
    
    del tensorList
    gpu_usage()
    #아직까진 메모리있음
    
    torch.cuda.empty_cache()
    gpu_usage()
    
    #메모리 비우기
    ```
    
- 학습시 OOM이 발생했다면 batch 사이즈를 1로 해서 실험해보기
- torch.no_grad()
    - Inference 시점에서는 torch.no_grad()구문을 사용
    - backward pass로 인해 쌓이는 메모리에서 자유로움